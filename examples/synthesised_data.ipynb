{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from tqdm.contrib import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from powershap import Powershap\n",
    "from itershap import IterSHAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "TRAIN_SAMPLES = 100\n",
    "NR_RUNS_PER_EXPEIMERNT = 5\n",
    "MAX_ITER = 3\n",
    "STEP_SIZE = 0.50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(TOTAL_SAMPLES, TOTAL_FEATURES, NR_INFORMATIVE, RANDOM_SEED):\n",
    "    # Create a synthesized classification dataset\n",
    "    X, y = make_classification(n_samples=TOTAL_SAMPLES, n_features=TOTAL_FEATURES, n_informative=NR_INFORMATIVE, n_redundant=0, shuffle=False, random_state=RANDOM_SEED)\n",
    "    column_names = np.array(['feature_'+str(f) for f in range(TOTAL_FEATURES)])\n",
    "    X = pd.DataFrame(X, columns=column_names)\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PowerSHAP\n",
    "For comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_shap(X, y):\n",
    "    X_train, X_test, y_train, _ = train_test_split(X, y, test_size=0.25)\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"selector\",\n",
    "                PowerShap(\n",
    "                    CatBoostClassifier(verbose=0, n_estimators=250, allow_writing_files=False),\n",
    "                ),\n",
    "            ),\n",
    "            (f\"CatBoostClassifier\", CatBoostClassifier(verbose=0, n_estimators=250, allow_writing_files=False)),\n",
    "        ]\n",
    "    )\n",
    "    pipe.fit(X_train, y_train)\n",
    "    X_test = pipe[0].transform(X_test)\n",
    "    SELECTED_FEATURES = X_test.columns    \n",
    "\n",
    "    return X.iloc[:, SELECTED_FEATURES]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "LARGE_DATASET = [False, True]\n",
    "TOTAL_SAMPLES_OPTIONS = [5000]\n",
    "TOTAL_FEATURES_OPTIONS = [20, 100, 250, 500]\n",
    "PERC_INFORMATIVE_OPTIONS = [0.10, 0.33, 0.50, 0.90]\n",
    "NR_RUNS_PER_EXPERIMENT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(S, F, I, LARGE, RS):\n",
    "    # Define the parameters of this experiment\n",
    "    TOTAL_SAMPLES = S\n",
    "    TOTAL_FEATURES = F\n",
    "    PERC_INFORMATIVE = I\n",
    "    NR_INF_FEATURES = math.floor(TOTAL_FEATURES * PERC_INFORMATIVE)\n",
    "    LARGE_DATA = LARGE\n",
    "    RANDOM_SEED = RS\n",
    "\n",
    "    # Retrieve the data for this experiment\n",
    "    X, y = get_data(TOTAL_SAMPLES, TOTAL_FEATURES, NR_INF_FEATURES, RANDOM_SEED)\n",
    "\n",
    "    if not LARGE_DATA:\n",
    "        X, y = train_test_split(X, y, train_size=160)\n",
    "\n",
    "    # Start time of the feature selection\n",
    "    powershap_start_time = time.time()\n",
    "    \n",
    "    # Iteratively reduce the features of the RF classifier\n",
    "    X_after_powershap = power_shap(X, y)\n",
    "    # Note the end time of the feature selection\n",
    "    powershap_end_time = time.time()\n",
    "    TOTAL_POWERSHAP_RUNTIME = time.time() - powershap_start_time\n",
    "\n",
    "    itershap_fs = IterSHAP(CatBoostClassifier)\n",
    "    itershap_fs.fit(X, y)\n",
    "    X_after_itershap = itershap_fs.transform()\n",
    "    TOTAL_ITERSHAP_RUNTIME = time.time() - powershap_end_time\n",
    "\n",
    "    # Test the outcoming accuracy on after Powershap feature selection\n",
    "    powershap_test_clf = CatBoostClassifier(verbose=0, n_estimators=250, allow_writing_files=False)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_after_powershap, y, test_size=0.25)\n",
    "    powershap_test_clf.fit(X_train, y_train)\n",
    "    y_pred_test = powershap_test_clf.predict(X_test)\n",
    "    POWERSHAP_ACCURACY = accuracy_score(y_test, y_pred_test)\n",
    "    print(f\"Accuracy after applying Powershap: \\t{POWERSHAP_ACCURACY}, in runtime \\t{TOTAL_POWERSHAP_RUNTIME}\")\n",
    "\n",
    "    # Test the outcoming accuracy on after IterSHAP feature selection\n",
    "    itershap_test_clf = CatBoostClassifier(verbose=0, n_estimators=250, allow_writing_files=False)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_after_itershap, y, test_size=0.25)\n",
    "    itershap_test_clf.fit(X_train, y_train)\n",
    "    y_pred_test = itershap_test_clf.predict(X_test)\n",
    "    ITERSHAP_ACCURACY = accuracy_score(y_test, y_pred_test)\n",
    "    print(f\"Accuracy after applying IterSHAP: \\t{ITERSHAP_ACCURACY}, in runtime \\t{TOTAL_ITERSHAP_RUNTIME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "    combinations = [[S, F, I, LARGE] for S in TOTAL_SAMPLES_OPTIONS for F in TOTAL_FEATURES_OPTIONS \n",
    "                    for I in PERC_INFORMATIVE_OPTIONS for LARGE in LARGE_DATASET]\n",
    "    # Loop over all combinations and add the results to the CSV.\n",
    "    for x, i in itertools.product(range(NR_RUNS_PER_EXPERIMENT), range(len(combinations))):\n",
    "        [S, F, I, LARGE] = combinations[i]\n",
    "        RANDOM_SEED = i + x*NR_RUNS_PER_EXPEIMERNT\n",
    "        print(f\"Running experiment: {RANDOM_SEED}\")\n",
    "        run_experiment(S, F, I, LARGE, RANDOM_SEED)\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
